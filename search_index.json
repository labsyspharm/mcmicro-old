[
["index.html", "Image Processing Pipeline Quick Start", " Image Processing Pipeline Laboratory of Systems Pharmacology Last Updated: 2019-11-19 Quick Start One-time installation command: bash /n/groups/lsp/cycif/mcmicro/O2_install.sh Run this once per dataset: sbatch --wait transfer.sbatch /n/data/ImStor/sorger/... /n/scratch2/abc123/PROJECT cd /n/scratch2/abc123/PROJECT cycif_pipeline_activate.sh /n/scratch2/abc123/PROJECT bash Run_CyCif_pipeline.sh For more detailed instructions, see the chapter on end-to-end pipeline execution. "],
["individual-module-documentation.html", "Individual module documentation", " Individual module documentation Stitch and register your images Segment your images to locate individual cells Extract spatial single cell features Assign cell type identities The instructions are under development as the LSP image processing pipeline matures. If you have a module that you would like to see included, please view the vignette on how to contribute to this guide. "],
["howto.html", "How To Contribute Synchronizing your fork with labsyspharm", " How To Contribute If you already have a fork from previous contributions, you may want to synchronize it with the live version. Go to https://github.com/labsyspharm/mcmicro and press “Fork” in the top right corner. In the Fork dialogue, select your personal GitHub account to fork the project to. Edit the .md files to add content. For formatting reference, see https://bookdown.org/yihui/bookdown/markdown-syntax.html If creating new .md files, add their filenames to _bookdown.yml. When finished, navigate to your personal fork (usually https://github.com/YourUsername/mcmicro) and press “New pull request”. Review the changes and press “Create pull request” when ready. Other teammates will review and comment on your changes. Once approved, the changes will appear on the live website. Synchronizing your fork with labsyspharm If you currently have no pending edits or open pull requests, the easiest thing to do is delete the fork and re-fork. Go to your personal fork, click on the Settings tab, scroll all the way to the bottom and press “Delete Repository”. Note that this will delete any work-in-progress. Proceed to step 2 above to re-fork labsysparm. If the live version has been updated while you are partway through contributing new content, you have to rebase your personal fork to incorporate the update. This requires you to clone the repository to a local machine, apply the rebase, and then push changes to GitHub. The following set of commands creates a local copy of your fork and sets up a pointer to the upstream repository (labsyspharm in this case). Replace YourUsername with your GitHub username. git clone https://github.com/YourUsername/mcmicro.git cd mcmicro git remote add upstream https://github.com/labsyspharm/mcmicro.git git remote -v The git remote -v command is there for verification. It should display origin pointing to your personal fork and upstream pointing to the labsyspharm fork. To rebase your personal fork, thus incorporating changes from upstream, can be done with the following commands: git fetch --all git rebase --ff-only upstream/master git push origin master "],
["pipeline.html", "1 End-to-end pipeline execution 1.1 Installation 1.2 Usage 1.3 Worked example using a sample dataset 1.4 Results 1.5 Visualize Images on Omero 1.6 Tips and Tricks 1.7 Frequently Asked Questions (FAQ) 1.8 Instructions for pipeline module developers", " 1 End-to-end pipeline execution Here we will walk you through running the default end-to-end processing pipeline comprising stitching and registration, segmentation, and single-cell feature extration. 1.1 Installation Run the following command to install the pipeline execution tools: bash /n/groups/lsp/cycif/mcmicro/O2_install.sh source ~/.bash_profile Run this command to check for success: which cycif_pipeline_activate.sh If you see /n/groups/lsp/cycif/mcmicro/bin/cycif_pipeline_activate.sh, the installation succeeded. If you see no cycif_pipeline_activate.sh in …` then the installation failed. If failed, contact someone from computational forum 1.2 Usage The commands below use the username abc123, so in the typed commands you must substitute your own username (or the username of whomever you’re working on behalf of). 1.2.1 Data transfer First you will need to setup an ssh Key so O2 can connect to the transfer server in order to transfer your data See Instructions in FAQ Next you will need to transfer your data to the scratch space (temporary high data volume storage): sbatch transfer.sbatch FROM /n/scratch2/abc123/PROJECT Replace FROM with the path to your data, and PROJECT with a short name for this project or experiment. We will refer to /n/scratch2/abc123/PROJECT as the “working directory”. See Folder Setup in Folder Organization Example 1.2.2 Go to the working directory cd /n/scratch2/abc123/PROJECT 1.2.3 Generate the pipeline execution script cycif_pipeline_activate.sh /n/scratch2/abc123/PROJECT 1.2.4 Launch the pipeline bash Run_CyCif_pipeline.sh 1.3 Worked example using a sample dataset sbatch --wait transfer.sbatch /n/groups/lsp/cycif/mcmicro/example_data/ /n/scratch2/abc123/example_data cd /n/scratch2/abc123/example_data cycif_pipeline_activate.sh /n/scratch2/abc123/example_data bash Run_CyCif_pipeline.sh Note that we have added the --wait option to the sbatch command which will pause until the data has finished transferring before continuing with the remaining steps. This is only practical if the dataset is small (less than about 50 GB). If your data is larger, see the Tips and Tricks section below. 1.4 Results Upon completion of the pipeline, the following folders will appear within your project directory containing the processed information from each part of the pipeline. The folders are: cell_states: Placeholder for future analysis clustering: Placeholder for future analysis dearray: Contains masks feature_extraction: The counts matrix of marker expression at a single cell level for all images (Output of HistoCAT software) illumination_profiles: Preprocessing files required for stitching the acquired raw tiles into a single image (Ashlar) prob_maps: Probability maps predicted by the UMAP deep learning algorithm for identifying nucleus, cell borders and background raw_files: Your original folder containing the raw images registration: Image that has been stitched and aligned over multiple cycles (needs to be uploaded to Omero for viewing or can be viewed using Image J) segmentation: Provides the location for the nuclei and a cell within an image 1.5 Visualize Images on Omero Transfer data to ImStor Import data to Omero 1.6 Tips and Tricks 1.6.1 Processing your own data 1.6.1.1 Folder Organization Example Project folder must be at a location findable by O2. (base) bionerd@MTS-LSP-L06275:~/Dana_Farber/CyCif/git/CyCif_O2_Manager/example_data$ pwd /home/bionerd/Dana_Farber/CyCif/git/CyCif_O2_Manager/example_data Within your data folder there are separate folders for each imaged slide. Can be whole tissue slide or TMA (eventually). (base) bionerd@MTS-LSP-L06275:~/Dana_Farber/CyCif/git/CyCif_O2_Manager/example_data$ ll drwxrwxrwx 1 bionerd bionerd 4096 Aug 9 08:03 image_1/ drwxrwxrwx 1 bionerd bionerd 4096 Aug 9 08:04 image_2/ Each folder should contain a subfolder: ‘raw_files’ with where for each CyCIF cycle there should the raw images from the microscope for example from Rare Cycte: ‘.rcpnl’ and ‘.metadata’ (base) bionerd@MTS-LSP-L06275:~/Dana_Farber/CyCif/git/CyCif_O2_Manager/example_data$ ll image_1/ total 0 drwxrwxrwx 1 bionerd bionerd 4096 Aug 9 10:44 ./ drwxrwxrwx 1 bionerd bionerd 4096 Aug 7 12:19 ../ drwxrwxrwx 1 bionerd bionerd 4096 Aug 9 08:04 raw_files/ [ntj8@login01 image_1]$ cd raw_files/ [ntj8@login01 raw_files]$ ll total 3326644 -rwxrwx--- 1 ntj8 ntj8 11516 Jul 9 17:30 Scan_20190612_164155_01x4x00154.metadata -rwxrwx--- 1 ntj8 ntj8 1703221248 Jul 9 17:31 Scan_20190612_164155_01x4x00154.rcpnl -rwxrwx--- 1 ntj8 ntj8 11524 Jul 9 17:31 Scan_20190613_125815_01x4x00154.metadata -rwxrwx--- 1 ntj8 ntj8 1703221248 Jul 9 17:32 Scan_20190613_125815_01x4x00154.rcpnl After the CyCIF Pipeline is run there will be additional folders created for each slide (explained in Results). 1.6.1.2 Requirements Can be run either locally or on O2. For O2, user must have an O2 account and be a member of the ImStor_sorger groups. Run groups on O2 to check. Request O2 account and group access at https://rc.hms.harvard.edu/. For the moment, you are responsible for transferring the data to the scratch space Data follows Folder Organization (shown above). File ‘markers.csv’ containing one marker per row, in the order imaged. Example: DNA1 AF488 AF555 AF647 DNA2 mLY6C mCD8A mCD68 File ‘data.yaml’ listing what parameters to use for pipeline execution (If you are unsure, just use the current ones) Example: --- Run: Name: &#39;CyCif Example&#39; TMA: False cf25: False file_extension: .rcpnl QC: Illumination: lambda_flat: 0.1 lambda_dark: 0.01 estimate_flat_field_only: False max_number_of_fields_used: None Stitcher: -m: 30 --filter-sigma: 0 Probability_Mapper: dapi_channel: 0 hs_scaling: 1 vs_scaling: 1 Segmenter: HPC: true fileNum: 1 TissueMaskChan: [2] #must include brackets logSigma: [3 30] #must include brackets mask: tissue segmentCytoplasm: ignoreCytoplasm Feature_Extractor: mask : cellMask.tif expansionpixels : 5 neighborhood : no 1.7 Frequently Asked Questions (FAQ) 1.7.1 Help my O2 environment changed! O2 loads in .bash_profile then .bashrc by default unless .bash_profile does not exist. If your O2 environment has changed, it is likely that the installation instructions created .bash_profile. Solution is to replace the installation instructions from .bash_profile to .bashrc 1.7.2 How To Setup O2 SSH Key The following instructions take you through setting up a SSH Key on O2. (Official instructions for generating SSH key) The senario behind this is that in CyCIF pipeline, it is designed to first submit a job to transfer files from /n/files, get the job ID, and the following steps in the pipeline are dependent on the transfer job. And the SSH Key allows you to transfer files from /n/files using the transfer server with ssh rsync, without being prompted for password. So that you can put ssh rsync from n/files to /n/scratch2 into an sbatch script. And the job could hang until the transfer is complete, then it will run the rest of the script. 1.7.2.0.1 Note: Replace your_ecommons with your ecommons while you type in the commands. 1.7.2.1 Generate SSH Key On O2 login node $ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/your_ecommons/.ssh/id_rsa): Hit Enter ⏎ Enter passphrase (empty for no passphrase): Hit Enter ⏎ Enter same passphrase again: Hit Enter ⏎ Your identification has been saved in /home/your_ecommons/.ssh/id_rsa. Your public key has been saved in /home/your_ecommons/.ssh/id_rsa.pub. The key fingerprint is: a5:b5:38:73:b7:3c:a6:8a:1d:a8:bd:87:4e:be:33:21 your_ecommons@login01 The key&#39;s randomart image is: The following command copies the public key to your authorized_keys file: $ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 1.7.2.2 Change file and directory permissions On O2 login node $ chmod 0600 ~/.ssh/authorized_keys $ chmod 0700 ~/.ssh $ chmod 0711 /home/$USER 1.7.2.3 Testing On O2 login node $ srun -p interactive --pty -t 1:00:00 -n 2 bash srun: job 50830472 queued and waiting for resources srun: job 50830472 has been allocated resources $ rsync -Pav transfer:/n/files/ImStor/sorger/data/RareCyte/yc296/YC-20180711-bleached-for-15-min/ /n/scratch2/yc296/transfer_test/ created directory /n/scratch2/your_ecommons/transfer_test ./ CSS08_A-bleach-light-new-S100-MCM6-p57-LSP2-Scan_20180711_144802_01x4x00090.rcpnl 995391488 100% 95.99MB/s 0:00:09 (xfer#1, to-check=5/7) CSS08_B-bleach-light-new-S100-MCM6-p57-LSP2-Scan_20180711_144203_01x4x00110.rcpnl 1216587776 100% 90.51MB/s 0:00:12 (xfer#2, to-check=4/7) CSS08_C-bleach-light-old-S100-MCM6-p57-LSP1-Scan_20180711_143205_01x4x00100.rcpnl 1105989632 100% 90.95MB/s 0:00:11 (xfer#3, to-check=3/7) Scan_20180711_143205_01x4x00100.metadata 8344 100% 13.34kB/s 0:00:00 (xfer#4, to-check=2/7) Scan_20180711_144203_01x4x00110.metadata 9024 100% 14.35kB/s 0:00:00 (xfer#5, to-check=1/7) Scan_20180711_144802_01x4x00090.metadata 7636 100% 12.11kB/s 0:00:00 (xfer#6, to-check=0/7) sent 128 bytes received 3318399628 bytes 99056709.13 bytes/sec total size is 3317993900 speedup is 1.00 1.8 Instructions for pipeline module developers Updated your code? #need conda environment for git lfs (Instructions for O2) module load conda2/4.2.13 #activate the cycif pipeline environment (path source activate [path to mcmicro]/environments/cycif_pipeline #clones all developer code based on last update of mcmicro git submodule update [] Wish to add your method to pipeline? Contact Nathan. 1.8.1 Install &amp; Run Assumptions: Matlab Installed Linux Slurm HPC Environment Git Installed git clone https://github.com/labsyspharm/mcmicro.git Install conda environments [path to mcmmicro]/bin/install_environments.sh Downloads exemplar data to current directory [path to mcmmicro]/bin/mcmicro-download-exemplar-001.sh [path to mcmmicro]/bin/mcmicro-download-exemplar-002.sh Install module code: uses git submodules #need conda environment for git lfs (Instructions for O2) module load conda2/4.2.13 #activate the cycif pipeline environment (path source activate [path to mcmicro]/environments/cycif_pipeline #clones all developer code based on last update of mcmicro git submodule update --init --recursive #update to latest version (can update to latest version of developer code, but may have been tested) git submodule update --recursive #alt way to update to latest git repo version if submodule update doesn&#39;t update git pull --recurse-submodules 1.8.2 Building the Conda Environments Instructions for building the ashlar and ashlar_c25 environments are present in mcmicro/bin/ashlar_cf25_update.sh and mcmicro/bin/ashlar_update.sh "],
["stitch.html", "2 Image Stitching and Registration 2.1 Input 2.2 Output 2.3 Installation 2.4 Usage 2.5 Example 2.6 More details 2.7 References", " 2 Image Stitching and Registration Raw CyCIF images must be stitched together and aligned across cycles before further processing. The tool we use to do this is Ashlar. 2.1 Input Image files for one or more cycles, in a BioFormats compatible format where metadata for pixel physical size and image stage positions are available. The RareCyte, InCell 6000, and DeltaVision microscopes are fully supported, and IXM support is currently in progress. RareCyte: Each cycle is fully contained in one .rcnpl file. InCell 6000: Each cycle is stored as many .tif files and one .xdce file. Use the .xdce file as the input for Ashlar. DeltaVision: Each cycle is fully contained in one .dv file. Shading correction profiles for all channels in each cycle. These profiles can be computed using the BaSiC plugin for ImageJ. Eventually this functionality will be built into Ashlar, but for now use this ImageJ Python macro: imagej_basic_ashlar.py (see instructions in comments at the beginning of the script). The macro will take one CyCIF cycle and generate two .tif files, the multi-channel flat-field and dark-field profiles. You will need to run the macro on each cycle separately. 2.2 Output A single many-channel .ome.tif image covering the entire sample across all cycles. This image file can be used for further processing in this pipeline or imported into OMERO for visualization and sharing. 2.3 Installation For most users, the Docker container is the simplest option: docker pull labsyspharm/ashlar:latest Experienced Python users can install natively: pip install ashlar 2.4 Usage 2.4.1 Docker container If you are using Ashlar via the Docker container, you must first launch the container with the interactive (-i) and TTY (-t) options, as well as a volume (-v) argument that maps the directory containing your data to the /data directory inside the container. Here is an example command line, assuming your images live in /Volumes/ImStor/images: docker run labsyspharm/ashlar:latest -i -t -v /Volumes/ImStor/images:/data At this point you will be at a Bash prompt inside the container, with /data as your working directory. Continue with the instructions for native Python users below. 2.4.2 Native Python Below is the general format of the command line you should start with, filling in all of the arguments like filenames and channel numbers to match your own data. Ashlar has many command line options, but in the context of this pipeline only a limited subset are relevant. Other options may be helpful to correct certain stitching problems, but they will not be covered here. Note that in this command, ... just means “more of the same” and should not be typed literally. ashlar \\ cycle-1.ext cycle-2.ext ... \\ # List of image files, one per cycle (.rcpnl, .xdce, etc.) --ffp ffp-1.tif ffp-2.tif ... \\ # List of flat-field profile images, one per cycle --dfp dfp-1.tif dfp-2.tif ... \\ # List of dark-field profile images, one per cycle -c dna_channel \\ # 0-based index of channel with DNA stain (often 0) -o output_directory \\ # Output image destination location -f sample_name.ome.tif \\ # Filename for output image --pyramid \\ # Required to produce OME-TIFF output To manage this long command line it may be helpful to copy the above sample command into a Bash script file, edit the file to suit your data, and run the script with bash script.sh. However in the example below we will type the command directly. 2.5 Example $ ashlar \\ &gt; input/BP40/cycle1.rcpnl input/BP40/cycle2.rcpnl \\ &gt; --ffp shading/BP40-cycle1-ffp.tif shading/BP40-cycle2-ffp.tif \\ &gt; --dfp shading/BP40-cycle1-dfp.tif shading/BP40-cycle2-dfp.tif \\ &gt; -c 0 \\ &gt; -o output \\ &gt; -f BP40.ome.tif \\ &gt; --pyramid Cycle 0: reading input/BP40/cycle-1.rcpnl quantifying alignment error 1000/1000 aligning edge 38/38 Channel 0: merging tile 24/24 writing to output/BP40.ome.tif Channel 1: merging tile 24/24 writing to output/BP40.ome.tif Channel 2: merging tile 24/24 writing to output/BP40.ome.tif Channel 3: merging tile 24/24 writing to output/BP40.ome.tif Cycle 1: reading input/BP40/cycle-2.rcpnl aligning tile 24/24 Channel 0: merging tile 24/24 writing to output/BP40.ome.tif Channel 1: merging tile 24/24 writing to output/BP40.ome.tif Channel 2: merging tile 24/24 writing to output/BP40.ome.tif Channel 3: merging tile 24/24 writing to output/BP40.ome.tif Building pyramid Level 1: processing channel 8/8 Level 2: processing channel 8/8 Level 3: processing channel 8/8 2.6 More details https://github.com/labsyspharm/ashlar 2.7 References (In progress) "],
["segment.html", "3 Image Segmentation 3.1 Image Preprocessing 3.2 Probability map binarization", " 3 Image Segmentation Segmentation consists of two distinct steps: Pre-processing of images to generate probability maps for background, nuclei contours and nuclei centers. Binarizing the resulting probability maps to identify pixel regions corresponding to individual cells. 3.1 Image Preprocessing The current tool for image preprocessing is UnMicst (UNet Model for Identifying Cells and Segmenting Tissue). Images can be preprocessed by inferring nuclei contours via a pretrained UNet model. The model is trained on 3 classes : background, nuclei contours and nuclei centers. The resulting probability maps can then be loaded into any modular segmentation pipeline that may use (but not limited to) a marker controlled watershed algorithm. The only input file is: an .ome.tif or .tif (preferably flat field corrected, minimal saturated pixels, and in focus. The model is trained on images acquired at 20x with binning 2x2 or a pixel size of 0.65 microns/px. If your settings differ, you can upsample/downsample to some extent. How to install: 1. Copy the python script, UNet model, and ImageScience toolbox to your computer. Clone from https://github.com/HMS-IDAC/UnMicst.git 2. Pip install tensorflow (or tensorflow_gpu with CUDA drivers and CuDNN libraries), matplotlib, scikit-image, Pillow, tifffile, Image, scipy How to run: 3. Open the python script batchUNet2DtCycif.py in an editor. 4. Make the following changes to the code to reflect the locations of your data and supporting files: -line 10 update the path to the ImageScience toolbox folder sys.path.insert(0, 'path//to//UNet code//ImageScience') -line 509 update the path to the model modelPath = 'modelPath = 'path//to//UNet code//TFModel - 3class 16 kernels 5ks 2 layers' -line 515 update the path to the top level experiment folder of the data imagePath = 'path//to//parent//folder//of//data' your files should be stored in a subfolder called registration -line 516 : if you have multiple samples and they have a similar prefix, add the prefix/suffix here: sampleList = glob.glob(imagePath + '//105*') -line 520 : if your files have a different extension from tif, you can change the extension here: fileList = glob.glob(iSample + '//registration//*.tif') some helpful tips: 5. -line 517 - specify the channel to infer nuclei contours and centers. If you want to run UNet on the 1st channel (sometimes DAPI/Hoechst), put 0. -line 518 - if you acquired your images at a higher magnification (ie. 40x), you may want to downsample your image so that it is more similar to the trained model (ie. 20x binning 2x2, pixel size 0.65 microns). in your terminal, activate your virtual environment and run this python script: python batchUNet2DtCycif.py If using tensorflow-gpu, your GPU card should be found. If not, prepare to hear your CPU fan fly! The probabilty map for the contours will be saved as a 3D tif file (concatenated with the original channel) and saved in a subfolder called `probmaps. The channel index you specified for inference is saved in the filename. References: S Saka, Y Wang, J Kishi, A Zhu, Y Zeng, W Xie, K Kirli, C Yapp, M Cicconet, BJ Beliveau, SW Lapan, S Yin, M Lin, E Boyde, PS Kaeser, G Pihan, GM Church, P Yin, Highly multiplexed in situ protein imaging with signal amplification by Immuno-SABER, Nat Biotechnology (accepted) 3.2 Probability map binarization S3segmenter is a Matlab-based set of functions that generates single cell (nuclei and cytoplasm) label masks. Inputs are: an .ome.tif (preferably flat field corrected) a 3-class probability maps derived from a deep learning model such as UNet. Classes include background, nuclei contours, and nuclei foreground. The centers of each nuclei are obtained by finding local maxima from the nuclei foreground. These are used for marker-controlled watershed constrained by the nuclei contours. To segment cytoplasm, the nuclei are in turn used for a marker-controlled watershed segmentation constrained by a cytoplasmic marker such as B-catenin. The channel number of this marker must be specified. A 3-pixel annulus around each nucleus will also be used to segment cytoplasm. How to run: In Matlab, set path to the folder of the cloned repo. Type: O2batchS3segmenterWrapperR('/path/to/files/') Use the following name-value pairs arguments to customize the code to your experiment: ip.addParamValue(&#39;HPC&#39;,&#39;false&#39;,@(x)(ismember(x,{&#39;true&#39;,&#39;false&#39;}))); % if using a cluster, this specifies which file index to work on ip.addParamValue(&#39;fileNum&#39;,1,@(x)(numel(x) &gt; 0 &amp; all(x &gt; 0 ))); % select any number of channels for cytoplasm ip.addParamValue(&#39;CytoMaskChan&#39;,[2],@(x)(numel(x) &gt; 0 &amp; all(x &gt; 0 ))); % select any number of channels for tissue mask ip.addParamValue(&#39;TissueMaskChan&#39;,[3],@(x)(numel(x) &gt; 0 &amp; all(x &gt; 0 ))); % constrict the tissue mask to eliminate high autofluorescent regions ip.addParamValue(&#39;RefineTissueMask&#39;,[0],@(x)(numel(x) &gt; 0 &amp; all(x &gt; 0 ))); % set to true if sample is TMA cores ip.addParamValue(&#39;mask&#39;,&#39;tissue&#39;,@(x)(ismember(x,{&#39;TMA&#39;,&#39;tissue&#39;,&#39;none&#39;}))); % interactiveCrop - a GUI-based crop selector, % &#39;autoCrop&#39; - takes the middle third region, % &#39;dearray&#39;, set to true if using TMA cores, % &#39;noCrop&#39;, no cropping ip.addParamValue(&#39;crop&#39;,&#39;noCrop&#39;,@(x)(ismember(x,{&#39;interactiveCrop&#39;,&#39;autoCrop&#39;,&#39;dearray&#39;,&#39;noCrop&#39;}))); ip.addParamValue(&#39;cytoMethod&#39;,&#39;distanceTransform&#39;,@(x)(ismember(x,{&#39;RF&#39;,&#39;distanceTransform&#39;,&#39;bwdistanceTransform&#39;,&#39;ring&#39;}))); % feature to threshold nuclei. % &#39;IntPM&#39; - intensity of probability map, % &#39;Int&#39; - intensity of DAPI channel, % &#39;LoG&#39;, intensity of LoG filter response, % &#39;none&#39;, accept all nuclei ip.addParamValue(&#39;nucleiFilter&#39;,&#39;IntPM&#39;,@(x)(ismember(x,{&#39;LoG&#39;,&#39;Int&#39;,&#39;IntPM&#39;,&#39;none&#39;}))); % extracts intensity features from mask ip.addParamValue(&#39;measureFeatures&#39;,&#39;false&#39;,@(x)(ismember(x,{&#39;true&#39;,&#39;false&#39;}))); ip.addParamValue(&#39;nucleiRegion&#39;,&#39;watershedContourInt&#39;,@(x)(ismember(x,{&#39;watershedContourDist&#39;,&#39;watershedContourInt&#39;,&#39;watershedBWDist&#39;,&#39;dilation&#39;}))); ip.addParamValue(&#39;resizeFactor&#39;,1,@(x)(numel(x) == 1 &amp; all(x &gt; 0 ))); % specify range of nuclei diameters in pixels ie [3 30]. ip.addParamValue(&#39;logSigma&#39;,[2.5],@(x)(numel(x) &gt;0 &amp; all(x &gt; 0 ))); % channels for measuring features. If 0, assume all channels. ip.addParamValue(&#39;chanRange&#39;,[0],@(x)(numel(x) &gt;0 &amp; all(x &gt; 0 ))); ip.addParamValue(&#39;upSample&#39;,2,@(x)(numel(x) == 1 &amp; all(x &gt; 0 ))); ip.addParamValue(&#39;Docker&#39;,&#39;false&#39;,@(x)(ismember(x,{&#39;true&#39;,&#39;false&#39;}))); ip.addParamValue(&#39;dockerParams&#39;,0,@(x)(numel(x)==1)); Segmentation label masks for nuclei, cytoplasm, and cell will be saved to a subfolder under each parent image folder as a .tif file. Also saved are a 2-channel tif file with the DAPI and nuclei outlines for quality control. References: S Saka, Y Wang, J Kishi, A Zhu, Y Zeng, W Xie, K Kirli, C Yapp, M Cicconet, BJ Beliveau, SW Lapan, S Yin, M Lin, E Boyde, PS Kaeser, G Pihan, GM Church, P Yin, Highly multiplexed in situ protein imaging with signal amplification by Immuno-SABER, Nat Biotechnology (accepted) "],
["features.html", "4 Extract spatial single cell features", " 4 Extract spatial single cell features Once the image is segmented label masks for nuclei, cytoplasm and full cell outline can be used to extract spatial single cell features. Expected input: .tif (16/32 bit) label mask for nuclei, cytoplasm or full cell outline (only one mask can be used per run) .ome.tif stitched image .csv including all channels corresponding to the ome.tif Expected output: .csv including all quantified spatial single cell features How to install: Clone histoCAT headless version from https://github.com/DenisSch/histoCAT Command line: git clone https://github.com/DenisSch/histoCAT How to run: % Run locally or remotly Headless_histoCAT_loading... (samplefolders_str,... % Path to OME.TIF image tiff_name,... % OME.TIF image name segmentationfolder_str,... % Path to .TIF mask mask_name,... % .TIF mask name Marker_CSV,... % .CSV including all channels corresponding to the OME.TIF expansionpixels,... % How many pixels should be used for extraction of spatial features neighbors)` % Should neighborhood / neighbors be calculates (e.g. for neighborhood analysis) Example: Headless_histoCAT_loading... (&#39;headless_Test/&#39;,... &#39;Example.tif&#39;,... &#39;headless_Test/&#39;,... &#39;Mask.tif&#39;,... &#39;headless_Test/Triplet_40_markers.csv&#39;,&#39;30&#39;,&#39;yes&#39;) More details: https://github.com/DenisSch/histoCAT References: https://www.nature.com/articles/nmeth.4391 "],
["celltype.html", "5 Assignment of cell type/state identity", " 5 Assignment of cell type/state identity Once segmentation masks have been quantified, the resulting cell-by-marker matrices can be used to assign cell type/state identity to individual cells. Methods to do this generally fall into two categories. The first set of methods typically begin by clustering cells into distinct subpopulations. The clusters are then inspected for the expression of specific markers, and cell type/state labeles are assigned to all cells belonging to that cluster. More sophisticated methods allow for “soft” assignment of cells to multiple clusters at once, which produces probabilistic assignment of cell types/states. The second class of methods forgo clustering entirely and work directly with the cell-by-marker matrix on a per-row (i.e., per-cell) basis. In the presence of labels, cell type assignment becomes a standard supervised learning task, where a model can be learned from labeled cells and applied to classify unlabeled ones. In the absence of labels, cell type assignment requires some prior knowledge about which markers map to which cell types/states. Given this mapping, assignment of cell identity can be done directly from marker expression. Expected input: An n-by-p matrix of n cells (rows) with quantified expression across p markers (columns) [optional] An n-by-1 vector of labels obtained through, e.g., manual curation [optional] A k-by-2 matrix that maps k channels to the corresponding cell type Expected output: An n-by-(p+1) matrix that encapsulates the original data with a new additional column denoting cell type assignments made by the method. In the case of probabilistic assigment, the method may output additional columns specifying per-class probabilities. Clustering-based methods Traditional supervised learning Method employing prior knowledge naivestates - Inference of cell states using a Naive Bayes framework. The method models each channel / marker as a mixture of two Gaussians. The resulting posterior probabilities of marker expression are combined with a pre-defined marker -&gt; cell type/state mapping to arrive at probabilistic assignment of cells to classes. IMAAP - Cell type annotation and analysis of multiplexed imaging data. The method models each marker as a mixture of two Gaussians and assigns a probability to the regions of uncertainty (where the gaussians intersect) to account for common segmentation errors. The assigned probabilities are then used to determine which cell type / state to which each cell belongs using a combination of user-defined markers. The method also includes data analysis and visualization functions. "]
]
